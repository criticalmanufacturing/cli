{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About cmf-cli","text":"<p>cmf-cli is a Command Line Interface used for Critical Manufacturing developments.</p>"},{"location":"#use-cmf-cli-to","title":"Use cmf-cli to . . .","text":"<ul> <li>Scaffold a new repository</li> <li>Generate new package structures</li> <li>Adapt packages of code for Critical Manufacturing MES</li> <li>Manage multiple versions of packages and package dependencies</li> <li>Create packages that can be used by any developer or customer</li> <li>View the package tree</li> <li>Restore packages for local development</li> <li>Assemble a release bundle</li> </ul> <p>and a lot more!</p>"},{"location":"#getting-started","title":"Getting started","text":"<p>To get started with cmf-cli, you need to use the command line interface (CLI) to install cmf-cli. We look forward to seeing what you create!</p>"},{"location":"install/","title":"Installation","text":"<p>To be able to install cfm-cli, you must install Node.js and the npm command line interface using either a Node version manager or a Node installer. We strongly recommend using a Node version manager like nvm to install Node.js and npm. We do not recommend using a Node installer, since the Node installation process installs npm in a directory with local permissions and can cause permissions errors when you run npm packages globally.</p> <pre><code>npm install --global @criticalmanufacturing/cli\n</code></pre>"},{"location":"install/#checking-your-version-of-cmf-cli-and-nodejs","title":"Checking your version of cmf-cli and Node.js","text":"<p>To see if you already have Node.js and npm installed and check the installed version, run the following commands:</p> <pre><code>node -v\ncmf -v\n</code></pre>"},{"location":"plugins/","title":"Plugins","text":"<p>The Critical Manufacturing cli is designed with a plugin system for extensibility. In the future, it will be possible to search for plugins straight from cli. Check issue #11 for progress.</p> <p>In the meanwhile, some plugins are already in development. Here follows a non-exaustive plugin list:</p> <ul> <li>Portal SDK - command line tools to interact with the Critical Manufacturing Customer Portal</li> </ul>"},{"location":"telemetry/","title":"Telemetry","text":""},{"location":"telemetry/#telemetry-implementation","title":"Telemetry implementation","text":"<p>Basic telemetry currently only tracks the CLI startup and logs:</p> <ul> <li>CLI name and version</li> <li>latest version available in NPM</li> <li>if the CLI version is stable or testing</li> <li>if the CLI is outdated</li> </ul> <p>no identifiable information is collected in basic telemetry</p> <p>However, any user can optionally enable extended telemetry, which might help with troubleshooting. Extended telemetry includes identifiable information and as such should be used with care. This includes the basic telemetry, plus:</p> <ul> <li>for the version (startup) log, it also includes<ul> <li>current working directory</li> <li>hostname</li> <li>IP</li> <li>username</li> </ul> </li> </ul> <p>It also tracks and logs the package tree if, for any command, the tree must be computed. This includes all of the above information plus the package name, for each package in the tree.</p> <p>Enabling telemetry can be done via environment variables:</p> <ul> <li><code>cmf_cli_enable_telemetry</code> - enable basic telemetry. If this is off (the default), no telemetry will be collected, even if extended telemetry is on. To enable, set to <code>true</code> or <code>1</code>, do not set or set to <code>false</code> or <code>0</code> to disable.</li> <li><code>cmf_cli_enable_extended_telemetry</code> - enable extended telemetry. Note the above warnings regarding the impact of keeping this on. To enable, set to <code>true</code> or <code>1</code>, do not set or set to <code>false</code> or <code>0</code> to disable.</li> <li><code>cmf_cli_telemetry_enable_console_exporter</code> - also print the telemetry information to the console. This is for auditing or troubleshooting as it makes the console output extremely verbose</li> <li><code>cmf_cli_telemetry_host</code> - specify an alternate telemetry endpoint (if you're hosting your own)</li> </ul>"},{"location":"telemetry/#pipelines","title":"Pipelines","text":"<p>NOTE: The CI-Package pipeline is shipped with telemetry ON. The provided pipelines are built for Critical Manufacturing use and provided as an example for the user to build their own. As at CM we keep telemetry on for troubleshooting, the generated pipelines have telemetry on. To disable, search for the <code>cmf_cli_enable_telemetry</code> environment variable in the pipeline YAML and disable it.</p>"},{"location":"commands/assemble/","title":"assemble","text":""},{"location":"commands/assemble/#usage","title":"Usage","text":"<pre><code>cmf assemble [options] [&lt;workingDir&gt;]\n</code></pre>"},{"location":"commands/assemble/#arguments","title":"Arguments","text":"Name Description <code>&lt;workingDir&gt;</code> Working Directory [default: .]"},{"location":"commands/assemble/#options","title":"Options","text":"Name Description <code>-o, --outputDir &lt;outputDir&gt;</code> Output directory for assembled package [default: Assemble] <code>--cirepo &lt;cirepo&gt;</code> Repository where Continuous Integration packages are located (url or folder) <code>-r, --repo, --repos &lt;repos&gt;</code> Repository or repositories where published dependencies are located (url or folder) <code>--includeTestPackages</code> Include test packages on assemble <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/build/","title":"build","text":""},{"location":"commands/build/#usage","title":"Usage","text":"<pre><code>cmf build [options] [&lt;packagePath&gt;] [command]\n</code></pre>"},{"location":"commands/build/#arguments","title":"Arguments","text":"Name Description <code>&lt;packagePath&gt;</code> Package Path [default: .]"},{"location":"commands/build/#options","title":"Options","text":"Name Description <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/build/#commands","title":"Commands","text":"Name Description <code>help</code>"},{"location":"commands/build_help/","title":"build help","text":""},{"location":"commands/build_help/#usage","title":"Usage","text":"<pre><code>cmf build [&lt;packagePath&gt;] help [options] [command]\n</code></pre>"},{"location":"commands/build_help/#arguments","title":"Arguments","text":"Name Description <code>&lt;packagePath&gt;</code> Package Path [default: .]"},{"location":"commands/build_help/#options","title":"Options","text":"Name Description <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/build_help/#commands","title":"Commands","text":"Name Description <code>generateBasedOnTemplates</code> <code>generateMenuItems</code>"},{"location":"commands/build_help_generateBasedOnTemplates/","title":"build help generateBasedOnTemplates","text":""},{"location":"commands/build_help_generateBasedOnTemplates/#usage","title":"Usage","text":"<pre><code>cmf build [&lt;packagePath&gt;] help generateBasedOnTemplates [options]\n</code></pre>"},{"location":"commands/build_help_generateBasedOnTemplates/#options","title":"Options","text":"Name Description <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/build_help_generateMenuItems/","title":"build help generateMenuItems","text":""},{"location":"commands/build_help_generateMenuItems/#usage","title":"Usage","text":"<pre><code>cmf build [&lt;packagePath&gt;] help generateMenuItems [options]\n</code></pre>"},{"location":"commands/build_help_generateMenuItems/#options","title":"Options","text":"Name Description <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/bump/","title":"bump","text":""},{"location":"commands/bump/#usage","title":"Usage","text":"<pre><code>cmf bump [options] [&lt;packagePath&gt;] [command]\n</code></pre>"},{"location":"commands/bump/#arguments","title":"Arguments","text":"Name Description <code>&lt;packagePath&gt;</code> Package path [default: .]"},{"location":"commands/bump/#options","title":"Options","text":"Name Description <code>-v, --version &lt;version&gt;</code> Will bump all versions to the version specified <code>-b, --buildNr &lt;buildNr&gt;</code> Will add this version next to the version (v-b) <code>-r, --root &lt;root&gt;</code> Will bump only versions under a specific root folder (i.e. 1.0.0) <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/bump/#commands","title":"Commands","text":"Name Description <code>iot</code>"},{"location":"commands/bump_iot/","title":"bump iot","text":""},{"location":"commands/bump_iot/#usage","title":"Usage","text":"<pre><code>cmf bump [&lt;packagePath&gt;] iot [options] [command]\n</code></pre>"},{"location":"commands/bump_iot/#arguments","title":"Arguments","text":"Name Description <code>&lt;packagePath&gt;</code> Package path [default: .]"},{"location":"commands/bump_iot/#options","title":"Options","text":"Name Description <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/bump_iot/#commands","title":"Commands","text":"Name Description <code>configuration &lt;path&gt;</code> [default: .] <code>customization &lt;packagePath&gt;</code> [default: .]"},{"location":"commands/bump_iot_configuration/","title":"bump iot configuration","text":""},{"location":"commands/bump_iot_configuration/#usage","title":"Usage","text":"<pre><code>cmf bump [&lt;packagePath&gt;] iot configuration [options] [&lt;path&gt;]\n</code></pre>"},{"location":"commands/bump_iot_configuration/#arguments","title":"Arguments","text":"Name Description <code>&lt;path&gt;</code> Working Directory [default: .]"},{"location":"commands/bump_iot_configuration/#options","title":"Options","text":"Name Description <code>-v, --version &lt;version&gt;</code> Will bump all versions to the version specified <code>-b, --buildNrVersion &lt;buildNrVersion&gt;</code> Will add this version next to the version (v-b) <code>-md, --masterData</code> Will bump IoT MasterData version (only applies to .json) [default: False] <code>-iot</code> Will bump IoT Automation Workflows [default: True] <code>-pckNames, --packageNames &lt;packageNames&gt;</code> Packages to be bumped <code>-r, --root &lt;root&gt;</code> Specify root to specify version where we want to apply the bump <code>-g, --group &lt;group&gt;</code> Group of workflows to change, typically they are grouped by Automation Manager <code>-wkflName, --workflowName &lt;workflowName&gt;</code> Specific workflow to be bumped <code>-isToTag</code> Instead of replacing the version will add -$version [default: False] <code>-mdCustomization</code> Instead of replacing the version will add -$version [default: False] <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/bump_iot_customization/","title":"bump iot customization","text":""},{"location":"commands/bump_iot_customization/#usage","title":"Usage","text":"<pre><code>cmf bump [&lt;packagePath&gt;] iot customization [options] [&lt;packagePath&gt;]\n</code></pre>"},{"location":"commands/bump_iot_customization/#arguments","title":"Arguments","text":"Name Description <code>&lt;packagePath&gt;</code> Package Path [default: .]"},{"location":"commands/bump_iot_customization/#options","title":"Options","text":"Name Description <code>-v, --version &lt;version&gt;</code> Will bump all versions to the version specified <code>-b, --buildNrVersion &lt;buildNrVersion&gt;</code> Will add this version next to the version (v-b) <code>-pckNames, --packageNames &lt;packageNames&gt;</code> Packages to be bumped <code>-isToTag</code> Instead of replacing the version will add -$version [default: False] <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/init/","title":"init","text":""},{"location":"commands/init/#usage","title":"Usage","text":"<pre><code>cmf init [options] &lt;projectName&gt; [&lt;rootPackageName&gt; [&lt;workingDir&gt;]]\n</code></pre>"},{"location":"commands/init/#arguments","title":"Arguments","text":"Name Description <code>&lt;projectName&gt;</code> <code>&lt;rootPackageName&gt;</code> [default: Cmf.Custom.Package] <code>&lt;workingDir&gt;</code> Working Directory [default: .]"},{"location":"commands/init/#options","title":"Options","text":"Name Description <code>--version &lt;version&gt;</code> Package Version [default: 1.0.0] <code>-c, --config &lt;config&gt; (REQUIRED)</code> Configuration file exported from Setup [default: ] <code>--repositoryUrl &lt;repositoryUrl&gt; (REQUIRED)</code> Git repository URL <code>--deploymentDir &lt;deploymentDir&gt; (REQUIRED)</code> Deployments directory <code>--MESVersion &lt;MESVersion&gt; (REQUIRED)</code> Target MES version <code>--DevTasksVersion &lt;DevTasksVersion&gt; (REQUIRED)</code> Critical Manufacturing dev-tasks version <code>--HTMLStarterVersion &lt;HTMLStarterVersion&gt; (REQUIRED)</code> HTML Starter version <code>--yoGeneratorVersion &lt;yoGeneratorVersion&gt; (REQUIRED)</code> @criticalmanufacturing/html Yeoman generator version <code>--nugetVersion &lt;nugetVersion&gt; (REQUIRED)</code> NuGet versions to target. This is usually the MES version <code>--testScenariosNugetVersion &lt;testScenariosNugetVersion&gt; (REQUIRED)</code> Test Scenarios Nuget Version <code>--infra, --infrastructure &lt;infrastructure&gt;</code> Infrastructure JSON file [default: ] <code>--nugetRegistry &lt;nugetRegistry&gt;</code> NuGet registry that contains the MES packages <code>--npmRegistry &lt;npmRegistry&gt;</code> NPM registry that contains the MES packages <code>--azureDevOpsCollectionUrl &lt;azureDevOpsCollectionUrl&gt;</code> The Azure DevOps collection address <code>--agentPool &lt;agentPool&gt;</code> Azure DevOps agent pool <code>--agentType &lt;Cloud|Hosted&gt;</code> Type of Azure DevOps agents: Cloud or Hosted <code>--ISOLocation &lt;ISOLocation&gt;</code> MES ISO file [default: ] <code>--nugetRegistryUsername &lt;nugetRegistryUsername&gt;</code> NuGet registry username <code>--nugetRegistryPassword &lt;nugetRegistryPassword&gt;</code> NuGet registry password <code>--cmfCliRepository &lt;cmfCliRepository&gt;</code> NPM registry that contains the CLI <code>--cmfPipelineRepository &lt;cmfPipelineRepository&gt;</code> NPM registry that contains the CLI Pipeline Plugin <code>--releaseCustomerEnvironment &lt;releaseCustomerEnvironment&gt;</code> Customer Environment Name defined in DevOpsCenter <code>--releaseSite &lt;releaseSite&gt;</code> Site defined in DevOpsCenter <code>--releaseDeploymentPackage &lt;releaseDeploymentPackage&gt;</code> DeploymentPackage defined in DevOpsCenter <code>--releaseLicense &lt;releaseLicense&gt;</code> License defined in DevOpsCenter <code>--releaseDeploymentTarget &lt;releaseDeploymentTarget&gt;</code> DeploymentTarget defined in DevOpsCenter <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/ls/","title":"ls","text":""},{"location":"commands/ls/#usage","title":"Usage","text":"<pre><code>cmf ls [options] [&lt;workingDir&gt;]\n</code></pre>"},{"location":"commands/ls/#arguments","title":"Arguments","text":"Name Description <code>&lt;workingDir&gt;</code> Working Directory [default: .]"},{"location":"commands/ls/#options","title":"Options","text":"Name Description <code>-r, --repo, --repos &lt;repos&gt;</code> Repositories where dependencies are located (folder) <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/new/","title":"new","text":""},{"location":"commands/new/#usage","title":"Usage","text":"<pre><code>cmf new [options] [command]\n</code></pre>"},{"location":"commands/new/#options","title":"Options","text":"Name Description <code>--reset</code> Reset template engine. Use this if after an upgrade the templates are not working correctly. <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/new/#commands","title":"Commands","text":"Name Description <code>business &lt;workingDir&gt;</code> [default: ] <code>database &lt;workingDir&gt;</code> [default: ] <code>data &lt;workingDir&gt;</code> [default: ] <code>feature &lt;packageName&gt; &lt;workingDir&gt;</code> [default: ] <code>help &lt;workingDir&gt;</code> [default: ] <code>html &lt;workingDir&gt;</code> [default: ] <code>iot &lt;workingDir&gt;</code> [default: ] <code>securityPortal &lt;workingDir&gt;</code> [default: ] <code>test</code>"},{"location":"commands/new_business/","title":"new business","text":""},{"location":"commands/new_business/#usage","title":"Usage","text":"<pre><code>cmf new business [options] [&lt;workingDir&gt;]\n</code></pre>"},{"location":"commands/new_business/#arguments","title":"Arguments","text":"Name Description <code>&lt;workingDir&gt;</code> Working Directory [default: ]"},{"location":"commands/new_business/#options","title":"Options","text":"Name Description <code>--version &lt;version&gt;</code> Package Version [default: 1.0.0] <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/new_data/","title":"new data","text":""},{"location":"commands/new_data/#usage","title":"Usage","text":"<pre><code>cmf new data [options] [&lt;workingDir&gt;]\n</code></pre>"},{"location":"commands/new_data/#arguments","title":"Arguments","text":"Name Description <code>&lt;workingDir&gt;</code> Working Directory [default: ]"},{"location":"commands/new_data/#options","title":"Options","text":"Name Description <code>--version &lt;version&gt;</code> Package Version [default: 1.0.0] <code>--businessPackage &lt;businessPackage&gt;</code> Business package where the Process Rules project should be built [default: ] <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/new_database/","title":"new database","text":""},{"location":"commands/new_database/#usage","title":"Usage","text":"<pre><code>cmf new database [options] [&lt;workingDir&gt;]\n</code></pre>"},{"location":"commands/new_database/#arguments","title":"Arguments","text":"Name Description <code>&lt;workingDir&gt;</code> Working Directory [default: ]"},{"location":"commands/new_database/#options","title":"Options","text":"Name Description <code>--version &lt;version&gt;</code> Package Version [default: 1.0.0] <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/new_feature/","title":"new feature","text":""},{"location":"commands/new_feature/#usage","title":"Usage","text":"<pre><code>cmf new feature [options] &lt;packageName&gt; [&lt;workingDir&gt;]\n</code></pre>"},{"location":"commands/new_feature/#arguments","title":"Arguments","text":"Name Description <code>&lt;packageName&gt;</code> The Feature package name <code>&lt;workingDir&gt;</code> Working Directory [default: ]"},{"location":"commands/new_feature/#options","title":"Options","text":"Name Description <code>--version &lt;version&gt;</code> Package Version [default: 1.0.0] <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/new_help/","title":"new help","text":""},{"location":"commands/new_help/#usage","title":"Usage","text":"<pre><code>cmf new help [options] [&lt;workingDir&gt;] [command]\n</code></pre>"},{"location":"commands/new_help/#arguments","title":"Arguments","text":"Name Description <code>&lt;workingDir&gt;</code> Working Directory [default: ]"},{"location":"commands/new_help/#options","title":"Options","text":"Name Description <code>--version &lt;version&gt;</code> Package Version [default: 1.0.0] <code>--docPkg, --documentationPackage &lt;documentationPackage&gt; (REQUIRED)</code> Path to the MES documentation package <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/new_html/","title":"new html","text":""},{"location":"commands/new_html/#usage","title":"Usage","text":"<pre><code>cmf new html [options] [&lt;workingDir&gt;]\n</code></pre>"},{"location":"commands/new_html/#arguments","title":"Arguments","text":"Name Description <code>&lt;workingDir&gt;</code> Working Directory [default: ]"},{"location":"commands/new_html/#options","title":"Options","text":"Name Description <code>--version &lt;version&gt;</code> Package Version [default: 1.0.0] <code>--htmlPackage, --htmlPkg &lt;htmlPackage&gt; (REQUIRED)</code> Path to the MES Presentation HTML package <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/new_iot/","title":"new iot","text":""},{"location":"commands/new_iot/#usage","title":"Usage","text":"<pre><code>cmf new iot [options] [&lt;workingDir&gt;] [command]\n</code></pre>"},{"location":"commands/new_iot/#arguments","title":"Arguments","text":"Name Description <code>&lt;workingDir&gt;</code> Working Directory [default: ]"},{"location":"commands/new_iot/#options","title":"Options","text":"Name Description <code>--version &lt;version&gt;</code> Package Version [default: 1.0.0] <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/new_iot/#commands","title":"Commands","text":"Name Description <code>configuration &lt;path&gt;</code> [default: .] <code>customization &lt;packagePath&gt;</code> [default: .]"},{"location":"commands/new_test/","title":"new test","text":""},{"location":"commands/new_test/#usage","title":"Usage","text":"<pre><code>cmf new test [options]\n</code></pre>"},{"location":"commands/new_test/#options","title":"Options","text":"Name Description <code>--version &lt;version&gt;</code> Package Version [default: 1.0.0] <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/pack/","title":"pack","text":""},{"location":"commands/pack/#description","title":"Description","text":"<p>cmf pack is a package creator for the CM MES developments. It puts files and folders in place so that CM Deployment Framework is able to install them.</p> <p>It is extremely configurable to support a variety of use cases. Most commonly, we use it to pack the developments of CM MES customizations.</p> <p>Run <code>cmf pack -h</code> to get a list of available arguments and options.</p>"},{"location":"commands/pack/#important","title":"Important","text":"<p>cmf pack comes with preconfigured Steps per PackageType to run during the installation. This pre defined steps are assuming a restrict structure during the installation, this can be disabled using the flag <code>isToSetDefaultSteps:false</code> in your <code>cmfpackage.json</code>.</p>"},{"location":"commands/pack/#how-it-works","title":"How it works","text":"<p>When the cmf pack is executed it will search in the working directory, for a <code>cmfpackage.json</code> file, that then is serialized to the CmfPackage this will guarantee that the <code>cmfpackage.json</code> has all the valid and needed fields. Then it will get which is the PackageType, and based on that will generate the package.</p>"},{"location":"commands/pack/#usage","title":"Usage","text":"<pre><code>cmf pack [options] [&lt;workingDir&gt;]\n</code></pre>"},{"location":"commands/pack/#arguments","title":"Arguments","text":"Name Description <code>&lt;workingDir&gt;</code> Working Directory [default: .]"},{"location":"commands/pack/#options","title":"Options","text":"Name Description <code>-o, --outputDir &lt;outputDir&gt;</code> Output directory for created package [default: Package] <code>-f, --force</code> Overwrite all packages even if they already exists <code>-?, -h, --help</code> Show help and usage information"},{"location":"commands/restore/","title":"restore","text":""},{"location":"commands/restore/#description","title":"Description","text":"<p><code>cmf restore</code> allows fetching development dependencies from Deployment Framework (DF) packages, as an alternative to the stricter NuGet and NPM packages.</p>"},{"location":"commands/restore/#how-it-works","title":"How it works","text":"<p>Running this command, any dependencies defined in <code>cmfpackage.json</code> will be obtained from the configured repositories (either specified via command option or registed in the <code>repositories.json</code> file) and are then unpacked to the <code>Dependencies</code> folder inside the package. Then each solution can add references/link packages from the Dependencies folder.</p>"},{"location":"commands/restore/#usage","title":"Usage","text":"<pre><code>cmf restore [options] &lt;packagePath&gt;\n</code></pre>"},{"location":"commands/restore/#arguments","title":"Arguments","text":"Name Description <code>&lt;packagePath&gt;</code> Package path"},{"location":"commands/restore/#options","title":"Options","text":"Name Description <code>-r, --repo, --repos &lt;repos&gt;</code> Repositories where dependencies are located (folder) <code>-?, -h, --help</code> Show help and usage information"},{"location":"scaffolding/","title":"Scaffolding","text":""},{"location":"scaffolding/#pre-requisites","title":"Pre-requisites","text":"<p>Though <code>@criticalmanufacturing/cli</code> runs with the latest <code>node</code> version, to run scaffolding commands the versions required by the target MES version are mandatory.</p> <p>For MES v8, the recommended versions are:</p> <ul> <li>latest node 12 (Erbium)</li> <li>latest npm 6 (should come with node)</li> </ul> <p>Apart from those, scaffolding also needs the following dependencies: <pre><code>npm install -g windows-build-tools\nnpm install -g gulp@3.9.1\nnpm install -g yo@3.1.1\n</code></pre></p>"},{"location":"scaffolding/#infrastructure","title":"Infrastructure","text":"<p>Rarely changing information, possibly sensitive, like NuGet or NPM repositories and respective access credentials are considered infrastructure. More information on how to set up your own is available at Infrastructure</p>"},{"location":"scaffolding/#environment-config","title":"Environment Config","text":"<p>A valid MES installation is required to initialize your repository, either installed via Setup or via DevOps Center. For the Setup: - in the final step of the Setup, click Export to obtain a JSON file with your environment settings For DevOps Center: - Open your environment and click Export Parameters</p> <p>Both these files contain sensitive information, such as user accounts and authentication tokens. They need to be provided to the <code>init</code> command with: <pre><code>cmf init --config &lt;config file.json&gt; --infra...\n</code></pre></p>"},{"location":"scaffolding/#scaffolding-a-repository","title":"Scaffolding a repository","text":"<p>Let's start by cloning the empty repository. </p> <pre><code>git clone https://git.example/repo.git\n</code></pre> <p>Move into the repository folder</p> <pre><code>cd repo\n</code></pre> <p>For a classic project example, check the traditional structure documentation.</p> <p>For more advanced structures, you'll probably be using Features.</p>"},{"location":"scaffolding/#continuous-integration-and-delivery","title":"Continuous Integration and Delivery","text":"<p>The scaffolding templates provide a few pipelines designed for Azure DevOps. They work both in Azure DevOps Server and Azure DevOps Services.</p> <p>IMPORTANT: Only the pipelines for Pull Request and for Package generation (CI-Changes and CI-Package) are designed to run outside of Critical Manufacturing infrastructure. We currently do not support running the Continuous Delivery part of the pipelines in a client infrastructure.</p> <p>The YAML files are available in the Builds folder at the repository root. Next to them are some JSON files which contain the metadata for the pipelines in Azure DevOps format, which can be used by directly invoking the Azure DevOps API. These files are in git ignore and they should not be committed, as they can contain secrets in plain text, such as Nuget credentials.</p> <p>For CMFers: you can use an internal tool to import the pipeline metadata, as well as the branch policies. Check \"How To Import Builds\" in the COMMON wiki at Docs/Pipelines.</p> <p>The CD-Containers pipeline requires a secret to be created into the Azure DevOps library. Check more details in the pipeline import document.</p>"},{"location":"scaffolding/#manual-pipeline-import","title":"Manual Pipeline import","text":"<p>For non-CMFs, it's simple to import the pipelines. Check out this document.</p>"},{"location":"scaffolding/#external-users","title":"External Users","text":"<p>There is more available information for non-CMFers at External Users.</p>"},{"location":"scaffolding/external/","title":"Scaffolding and Pipelines for non-CMF Users","text":"<p>This document details a base approach on how to use <code>@criticalmanufacturing/cli</code> to scaffold a Product Customization solution if you are not in the CMF infrastructure. This guide assumes it is being executed in a Windows machine, but can be run in Linux with PowerShell Core if needed. Adapt as required.</p>"},{"location":"scaffolding/external/#notes-on-the-local-repository","title":"Notes on the Local Repository","text":"<p>In this document, it is assumed that the user has got a copy of the necessary packages from CMF. However, it is also possible that the user simply has access to the needed repositories. If this is the case, skip the repository setup steps.</p> <p>If the user is setting up their own repository, this guide is using the Sonatype Nexus v3 repo as an example. This repository provides hosting for NuGet, NPM and raw (i.e. Zip file) packages. Other repositories can be used, hosted together or not. However, it may be left to the user to determine the correct endpoints. In this document, it is assumed the local repository live at <code>example.local</code> and is an OSS Nexus v3.</p> <p>For hosting Nexus, the easiest way is to use the official Docker image. The setup of the repository is not detailed in this guide but information can be found in Sonatype's help page.</p> <p>The Nexus repository used in this guide needs to:</p> <ol> <li>Have a NuGet repository. In this guide it is called <code>nuget-hosted</code>. We do not use the proxy or grouped repository types, as the public packages are directly referenced from nuget.org</li> <li> <p>Have an NPM repository. In this guide it is called <code>npm</code> and is of type <code>npm-grouped</code>. Unlike NuGet, here we do setup proxy and grouped repositories. The configuration is as follows:</p> <ol> <li> <p>Hosted npm repository <code>npm-hosted</code>: this will contain the private CMF packages</p> </li> <li> <p>Proxy npm repository <code>npm-proxy</code>: this repository only proxies public package request to npmjs.org</p> </li> <li> <p>Grouped npm repository <code>npm</code>: this repository is a group of the <code>npm-hosted</code> and <code>npm-proxy</code> repositories.</p> </li> <li>In Settings &gt; Realms, have NPM Bearer Token and NuGet API Key realms active. The API Key can be obtained from the user profile.</li> </ol> </li> </ol>"},{"location":"scaffolding/external/#authentication","title":"Authentication","text":"<p>By default, NuGet and NPM repositories operate with anonymous access, requiring only credentials to publish. If this does not meet your requirements, you can opt to require authentication to all feeds.</p>"},{"location":"scaffolding/external/#nuget","title":"NuGet","text":"<ol> <li>In Nexus, go to Settings &gt; Security &gt; Anonymous Access and disable anonymous access.</li> <li> <p>When running <code>init</code>, provide an infrastructure file that contains the credentials like so:</p> <p>\"NuGetRegistryUsername\": \"\", \"NuGetRegistryPassword\": \"\" <p>If provided, the NuGet restore calls will be authenticated. Note that currently there is no way to do the restore using NuGet ApiKeys.</p>"},{"location":"scaffolding/external/#npm","title":"NPM","text":"<ol> <li> <p>login to your NPM repo with the build account (This is also done when publishing the packages but for the hosted repo. In this case the grouped repo must be used):</p> <pre><code>npm adduser --registry=http://example.local/repository/npm/\n</code></pre> </li> <li> <p>in the <code>.npmrc</code> file in your home folder, a new line should be added, in the format <code>//example.local/repository/npm/:_authToken=NpmToken.&lt;GUID&gt;</code></p> </li> <li> <p>take this line and add it to the <code>.npmrc</code> in both the Help and HTML solutions. The files are always in the <code>apps/&lt;web solution&gt;</code> path</p> </li> <li> <p>commit these files</p> </li> </ol> <p>NOTE: this file will be visible to anyone with source code access! If push permissions are not desired here, use an account that can only download packages!</p> <p>In some cases <code>npm adduser</code> may fail. A known case is when using Personal Access Tokens (PATs) instead of passwords in Windows systems. In these cases, it's possible to directly use the credentials without this authentication step:</p> <ol> <li> <p>edit the <code>.npmrc</code> file in the HTML and Help package directories with your text editor</p> </li> <li> <p>fill in the repository: <code>registry=https://example.io/repository/npm/</code></p> </li> <li> <p>fill in the credentials. The <code>_auth</code> string is obtained by doing a Base 64 encode of <code>&lt;user&gt;:&lt;password&gt;</code> with the respective username and password of the repository account: <code>//example.io/repository/npm/:_auth=\"&lt;base64 string&gt;\"</code></p> </li> <li> <p>tell NPM to always authenticate: <code>//example.io/repository/npm/:always_auth=true</code></p> </li> </ol> <p>So if your username is <code>user1</code> and your password is <code>secret2</code> the <code>.npmrc</code> files would look like <pre><code>registry=https://example.io/repository/npm/\n//example.io/repository/npm/:_auth=\"dQBzAGUAcgAxADoAcwBlAGMAcgBlAHQAMgA=\" //example.io/repository/npm/:always_auth=true\n</code></pre></p> <p>where the auth string can be generated in Powershell using <pre><code>[Convert]::ToBase64String([System.Text.Encoding]::Unicode.GetBytes(\"user1:secret2\"))\n</code></pre></p>"},{"location":"scaffolding/external/#process","title":"Process","text":""},{"location":"scaffolding/external/#host-packages-in-local-repository","title":"Host packages in local repository","text":"<p>If using a local repository, the dependency packages need to be hosted there. CMF will have provided a package with the NuGet packages. The NPM packages are extracted from the MES ISO file. The instructions are available either on your Help website or in CMF's general Help repository.</p> <p>However, currently the script provided in the Help tutorial only uploads the HTML solution dependencies, not the Help solution ones. As such, an updated copy of the script can be provided if requested.</p> <p>It is recommended that you follow the Help tutorial, but a few quick steps will be detailed here</p> <ol> <li> <p>Authenticate to your local repo: </p> <pre><code>npm adduser --registry=http://example.local/repository/npm-hosted/\n</code></pre> <ol> <li>NOTE: If using Nexus OSS, you will have to upload to the <code>npm-hosted</code> repo, not to <code>npm</code></li> </ol> </li> <li> <p>Run for each package (where the <code>package.json</code> is located)</p> <pre><code>npm publish --registry=http://example.local/repository/npm-hosted/ --force\n</code></pre> </li> </ol> <p>NOTE: You only need to specify the Username if you don't have anonymous access to your repository </p> <ol> <li>OPTIONAL: tag the loaded packages with the dist-tags used by the solutions. If this is not desired, the scaffolded solutions will have to be changed to point to the exact versions that are uploaded into the repository. Adding the dist-tags is generally easier. The dist-tags always follow the format <code>release-&lt;version&gt;</code> with no dots. As an example, for MES version 8.1.0 the dist-tag commands would be:<pre><code>npm dist-tag add @criticalmanufacturing/mes-ui-web@8.1.0-202103302 release-810 --registry=http://example.local/repository/npm-hosted/\n\nnpm dist-tag add cmf.docs.web@8.1.0-20210329.4 release-810 --registry=http://example.local/repository/npm-hosted/\n</code></pre> </li> </ol>"},{"location":"scaffolding/external/#loading-the-scaffolding-into-the-target-project","title":"Loading the scaffolding into the target project","text":""},{"location":"scaffolding/external/#using-a-local-repository","title":"Using a local repository","text":"<p>If using a local repository, the first step is to load the NuGet dependencies. Until this is done the Business and Test solutions will not compile. </p> <pre><code>cd &lt;folder&gt;\nnuget setapikey &lt;nuget key&gt; -source http://example.local/repository/nuget-hosted\n\n# for each nuget file:\nnuget push &lt;file.nupkg&gt; -source http://local.example/repository/nuget-hosted/\n</code></pre> <p>NOTE: Don't forget to authenticate first if you are not using an API Key.</p>"},{"location":"scaffolding/external/#commiting-the-code","title":"Commiting the code","text":"<p>If you did not run <code>init</code> and <code>new</code> inside a cloned git repository folder, you can add it as a remote in place. For the second approach, open a PS session where you ran the <code>init</code> and run:</p> <pre><code>git remote add origin https://&lt;user&gt;@dev.azure.com/&lt;organization&gt;/&lt;project&gt;/_git/&lt;repository&gt;\ngit push -u origin --all\n</code></pre>"},{"location":"scaffolding/external/#loading-pipelines-and-policies","title":"Loading pipelines and policies","text":"<p>To run the pipelines, some tasks need to be installed in Azure DevOps. These are:</p> <ul> <li>MSPremier.PostBuildCleanup.PostBuildCleanup-task.PostBuildCleanup</li> <li>qetza.replacetokens</li> </ul> <p>You can now load the Pipelines and Policies into your project.</p>"},{"location":"scaffolding/features/","title":"Feature package scaffolding","text":"<p>A traditional project structure targets the scenario where one team does all of the development for a project with a single target, e.g. a customization team deploying MES to a single factory or a set of factories with the exact same customization.</p> <p>However, some projects are more complex. A single team can target a multi-site deployment in which the sites target a set of common features, but complement them with site-specific features, or the common features need site-specific data packages to configure them.</p> <p>In these cases, projects are usually structured in a Feature Packages arrangement, in that some packages are self-contained, or in a Layered Project arrangement, in which e.g. a Site package, which is specific to a given site/plant, depends on a Core/Baseline package, which is common among all sites.</p> <p><code>cmf new</code> allows assembling these package in whatever structure is necessary, with a few limitations: - the test solution is always at the repository level, i.e. we do not have feature-level test packages - you cannot mix traditional packages, which exist in the repository root, with these packages - a feature package must always exist inside a global repository</p> <p><code>cmf new</code> will automatically register each package as a dependency of its parent (as per the folder structure).</p>"},{"location":"scaffolding/features/#initialize-the-repository","title":"Initialize the Repository","text":"<p>In case we are creating the first package in the repository, we need to initialize it in the same way as we do for a traditional project. Check the Initialize the repository section of the traditional scaffolding instructions.</p>"},{"location":"scaffolding/features/#creating-a-feature-package","title":"Creating a Feature Package","text":"<p>A Feature Package is a metapackage that can include one or more layer packages, e.g. we can have a Feature package that includes only a Business package.</p> <p>A Feature package should include all necessary layer packages (business, UI, Help) needed for the Feature to work.</p> <p>To create a new Feature Package, run the <code>new feature</code> command at your repository root, specifying the new package name: e.g. to create the Baseline package for your project, run:</p> <pre><code>cmf new feature Cmf.Custom.Baseline </code></pre> <p>The new feature package will be available in your repository at <code>Features\\Cmf.Custom.Baseline</code>.</p> <p>After creating a Feature package, it is not longer possible to create new layer packages in the repository root. Any <code>new</code> command for a layer package will fail:</p> <pre><code>&gt; cmf new html\n  Cannot create a root-level layer package when features already exist.\n</code></pre>"},{"location":"scaffolding/features/#creating-layer-packages-in-a-feature-package","title":"Creating Layer packages in a Feature package","text":"<p>Creating layer packages works exactly in the same way as for a traditional project, but the <code>cmf new</code> command should run from inside the feature package:</p> <pre><code>&gt; cd Features/Cmf.Custom.Baseline\n&gt; cmf new business\nThe template \"Business Package\" was created successfully.\n</code></pre> <p>The layer package name will include the feature package name fragment to distinguish it from other packages in the same repository.</p>"},{"location":"scaffolding/infrastructure/","title":"Infrastructure config file","text":""},{"location":"scaffolding/infrastructure/#structure","title":"Structure","text":"<p>Information regarding repositories and Azure projects usually don't change very often. For this set of information, <code>init</code> accepts a file with a few keys that specify:</p> <ol> <li>The NPM repository URL</li> <li>The NuGet repository URL</li> <li>The Azure DevOps collection URL</li> <li>The Azure DevOps project name</li> <li>The type of Azure build agents used, Cloud or Hosted<ol> <li>Cloud means Microsoft hosted agents with can run a multitude of VMs</li> <li>Hosted means self-hosted agents. Using self-hosted, for now, requires Windows agents with a set of pre-requisites installed.</li> </ol> </li> </ol>"},{"location":"scaffolding/infrastructure/#usage","title":"Usage","text":"<p>The infrastructure file must be passed to the <code>init</code> command as an argument, e.g.: <pre><code>cmf init --infrastructure &lt;file&gt; --config...\n</code></pre></p>"},{"location":"scaffolding/infrastructure/#example","title":"Example","text":"<pre><code>{\n\"ISOLocation\": \"path/to/MES/isos\",\n\"NPMRegistry\": \"http://local.example/repository/npm\",\n\"NuGetRegistry\": \"https://local.example/repository/nuget-hosted\",\n\"NuGetRegistryUsername\": \"user\",\n\"NuGetRegistryPassword\": \"password\",\n\"AzureDevopsCollectionURL\": \"https://azure.example.com/Projects\",\n\"AgentPool\": \"Projects\",\n\"AgentType\": \"Cloud\"\n}\n</code></pre>"},{"location":"scaffolding/migrationPaths/","title":"Migration Paths","text":""},{"location":"scaffolding/migrationPaths/#to-3x","title":"To 3x","text":"<p>Default Steps for Business and Data Packages are now inject by the cli. If you are upgrading to cmf-cli 3x you should remove all the steps from the following packages:</p> <ul> <li>Business</li> <li>Data</li> <li>IoTData</li> <li>Tests MasterData</li> </ul>"},{"location":"scaffolding/pipeline_import/","title":"Pipeline Import","text":"<p>To import the Continuous Integration pipelines, first make sure you have scaffolded your project successfully and can see a folder in the project root named Builds with several YAML files in it:</p> <p></p> <p>If so, we can proceed. Push your repository if you haven't yet. It is important that the default branch contains the pipeline YAML files. In our setup, the default branch is always development.</p> <p>For each of PR-Changes, PR-Package, CI-Changes and CI-Package, repeat these steps:</p> <ol> <li> <p>create a new pipeline</p> <p></p> </li> <li> <p>Choose Use the classic editor</p> <p></p> </li> <li> <p>Choose your Team Project, repository and default branch. Our generated pipelines are expecting the default branch to be development</p> <p></p> </li> <li> <p>After that, choose Configuration as code &gt; YAML</p> <p></p> </li> <li> <p>and choose the corresponding YAML file in the Builds folder</p> <p></p> </li> </ol>"},{"location":"scaffolding/pipeline_import/#pull-request-policies","title":"Pull Request policies","text":"<p>To effectively leverage the Pull Request flow our pipelines enable, Azure DevOps must be configured to protect the default (in our case, development) branch.</p> <p>Go to Repos &gt; Branches, on the development row, click the More button on the far right and select Branch Policies</p> <p></p> <p>The policy options per-se are dependent on the team configuration and working mode. Here is an example of our policies</p> <p></p> <p>The important point here is to set the PR-Changes pipeline to run whenever a Pull Request is opened. To do so, add a new row in Build validation that looks like this</p> <p></p> <p>This will ensure the PR pipelines will run each time code is pushed to a Pull Request, and will block merging if the build is failing.</p>"},{"location":"scaffolding/pipeline_import/#remaining-pipelines","title":"Remaining pipelines","text":"<p>We do not support running the Continuous Delivery pipelines in a client setting. These pipelines are strongly opinionated on the environment in which they run and require virtual machines configured specifically for them. They are still provided as an example and guide so that each client or partner can create their own pipelines. However, they will not work out of the box and will hang on permissions issues if attempted to run.</p>"},{"location":"scaffolding/pipeline_import/#secrets","title":"Secrets","text":"<p>The CD-Containers pipeline requires that a secret is specified in a variable group to run successfully. The most important one is the Customer Portal PAT (Personal Access Token). </p> <p></p> <ol> <li> <p>In Azure DevOps, go to Pipelines &gt; Library and create a new Variable Group</p> </li> <li> <p>Name the variable group \"Docker Variables\"</p> </li> <li> <p>Check \"Allow access to all pipelines\"</p> </li> <li> <p>Add a new variable named CustomerPortalPAT and paste your Customer Portal PAT as the value</p> </li> <li> <p>Click the lock icon to turn the variable into a secret</p> </li> <li> <p>Save the variable group</p> </li> </ol> <p>The pipeline will automatically use the variable group.</p> <p>It is possible to add extra secrets or variables into this group, to preserve some secrets from the environment settings. Any token in the format e.g. <code>#{aToken}#</code> will be replaced with the value of the aToken variable.</p>"},{"location":"scaffolding/pipelines/","title":"Pipelines description","text":"<p>This page gives an overview of our pipeline design and working mode. For specific details, you can consult the generated pipelines, by running the <code>cmf init</code> command as detailed here.     </p> <p>Please remember that these pipelines are tailored to CM's internal structure and are not expected to run unmodified in your infrastructure. They are provided as examples and should not replace your own pipelines adapted to you specific process.</p>"},{"location":"scaffolding/pipelines/#pull-request-pr-process","title":"Pull Request (PR) process","text":"<p>The Pull Request process runs each time a Pull Request is opened or code is pushed to the request branch. It is comprised of two pipelines.</p>"},{"location":"scaffolding/pipelines/#pr-changes","title":"PR-Changes","text":"<p>The PR-Changes pipeline calculates which packages are affected by which git commits. It does this by comparing the HEAD commit of each <code>cmfpackage.json</code> file in the repository between the PR branch and the target branch. For each changed package, a PR-Package pipeline run is triggered.</p>"},{"location":"scaffolding/pipelines/#pr-package","title":"PR-Package","text":"<p>This pipeline builds the package by invoking <code>cmf build --test</code>, making sure the changed packages build and their unit tests pass. If this build fails, the Pull Request is blocked. The developer then has to correct the code, push it to the PR branch, and the process starting with PR-Changes will run again automatically to validate the code.</p>"},{"location":"scaffolding/pipelines/#continuous-integration-ci-process","title":"Continuous Integration (CI) process","text":"<p>Our CI process consists of 2 pipelines responsible for generating packages anytime our main branch changes. </p>"},{"location":"scaffolding/pipelines/#ci-changes","title":"CI-Changes","text":"<p>The CI-Changes pipeline calculates which packages are affected by which git commits. It does this by comparing the last built HEAD for that specific package. For each altered package, a run of CI-Package is triggered.</p>"},{"location":"scaffolding/pipelines/#ci-package","title":"CI-Package","text":"<p>This pipeline builds the package specified by its parameters, which are filled in automatically by CI-Changes.</p> <p>The build process happens exclusively using the <code>cmf</code> CLI tool. The pipeline invokes <code>cmf build --test</code>, which builds the package and runs its automatic test suite. If successful on both steps, it then invokes <code>cmf pack</code> to generate a package that can be installed via DevOps Center or Critical Manufacturing Setup. This package is then placed in the CI repository (as defined in the variable CIPackages in <code>GlobalVariables.yml</code>) and the current git HEAD is registered as the last built HEAD for this package.</p> <p>The pipeline process has no bearing on the package name: each package name and version are specified in their manifest (<code>cmfpackage.json</code>) file. As such, when developing new functionality on a released package, don't forget to bump its version first, regarding the type of the changes to bump the patch, minor or major numbers. The PR process will not allow merging a package with an ID/Version pair which has already been approved for release.</p>"},{"location":"scaffolding/pipelines/#ci-publish","title":"CI-Publish","text":"<p>At least once a day, this pipeline runs to calculate which packages should be included in a release run for E2E testing.</p> <p>It does this by calculating our current package tree, starting from root, and checking which of these packages are already present in the Deployed repository. If they exist there, they were already released and should not be considered release candidates. All remaining packages are release candidates and should be included in a release run. This calculation is performed entirely by the <code>cmf</code>  CLI tool, using the <code>cmf assemble</code> command.</p> <p>The release candidates are packed and published as a build artifact, as our Package artifact. As well, the environment configurations are packed into our Configurations artifact, and the relevant test packages are packed as our Tests artifact.</p>"},{"location":"scaffolding/pipelines/#continuous-delivery-cd-process","title":"Continuous Delivery (CD) process","text":"<p>Our CD process doesn't actually deliver to client environments, but to our production-like Integration environments. It can be executed by one of two pipelines, depending if we're targeting a Windows machine or a Container installation. However, both pipelines implement different approaches to the same process:</p> <ol> <li>Restore the environment to a previous known good state - this can be either the same MES and customization version currently running in Production at the client if we're building cumulative packages (not recommended) or the last sprint's delivered versions for client testing when building iterative packages.</li> <li>Install Release Candidate packages, and their MES dependency if needed - perform the actual package installations.</li> <li>Create an environment restore point - this restore point will be used the next known good state if these release candidates are approved for release.</li> <li>Load test master data - load additional data that helps with testing.</li> <li>Create the Daily backup - backup only the ONLINE database, for development use. This backup can be loaded locally in our development machines to support our local environments. It contains the test master data, which is useful for development tests.</li> <li>Run E2E tests - run the tests that require the full environment to be installed. We run the Backend, Frontend and IoT tests separately, though this is a technicality.</li> <li>Approval gate - this is a manual step. If the team is happy with this run and with the quality of the Release Candidate packages, this run can be approved and the release candidate packages can be released to the client. </li> <li>Set Known Good State - this only runs if the run is approved. It will set the Restore Point created in step 3 as the known good state for the next run.</li> </ol> <p>The pipelines are as follows:</p>"},{"location":"scaffolding/pipelines/#ci-release-for-windows-machine-installations","title":"CI-Release (for Windows machine installations)","text":"<p>This pipeline needs to backup the entire MES installation. As such, both the database and application layers are backed-up. The tool most used in this process is the CmfDeploy client, which is part of the Deployment Framework that ships in the Critical manufacturing disks/ISOs. The details of each step are:</p> <ol> <li>restore - this uses the Cmf.BackupRestore.Tools (installed via CmfDeploy) to restore both the database and the application layer to the backed-up state. <ol> <li>Running CmfDeploy uses Powershell remoting to mount the ISO file in the target machine and run the installation from there, as this is a requirement when changing the application layer. This is true for all steps. <p>Beware that the application layer part includes only the business tier, the HTML and Help sites. Which means these restores do not work if the MES version changes: if we upgraded MES and then restored to a backup in a previous version, we'd get a mixed environment that will most likely break.</p> </li> </ol> </li> <li>Install the Release Candidate root package using CmfDeploy. All already installed packages will be skipped, and only new packages will be installed.</li> <li>Use Cmf.backupRestore.Tools to create a temporary restore point including all databases and application the 3 layer solutions (check the NOTE at step 1).</li> <li>Load the test master data files (using CmfDeploy). The test master data files are also DF packages, though not usually shipped to the client. They are installed the same way as the actual system upgrades.</li> <li>Create the Daily backup - use CmfDeploy with Cmf.BackupRestore.Tools to backup only the ONLINE database</li> <li>Run E2E tests - this is the only part that runs on the build server: it uses the VsTest azure task to run all E2E tests, from each layer in turn, Business, HTML, IoT.</li> <li>Approval Gate</li> <li>Set Known Good State - rename and move the backups so they are picked up by the next run</li> </ol>"},{"location":"scaffolding/pipelines/#cd-containers","title":"CD-Containers","text":"<p>Unlike the Windows machine pipeline, this pipeline always reinstalls MES by using brand new containers. This makes the process more reliable and the backups quicker. The most used tool in this process is <code>portal-sdk</code>, a <code>cmf</code> CLI plugin that can be installed from <code>npm</code>.</p> <ol> <li>restore - for containers, we don't actually restore anything, we simply drop all databases to reinstall MES</li> <li>Installation - create a new version of our Integration stack by using the portal-sdk plugin. Set as target package the release candidate root package. This package depends on a specific MES versio which will get installed first. This installation also uses the Known Good State backups to maintain the database contents as they were on the last approved release run.</li> <li>Use CmfDeploy to create a temporary database backup, by using the CmfDeploy <code>backup</code> command.</li> <li>Load the test MD by creating a new version of our environment using as target the Test MD package. If we have multiple test MD packages, we do this once for each one.</li> <li>Create the Daily backup by the exact same process as step 3, but only backup the ONLINE database.</li> <li>Run E2E tests - this is similar to the Windows machine scenario</li> <li>Approval Gate</li> <li>set know good state, by moving the backups created in step 3 (ONLINE, ODS and DWH) to a known location which the next run will use as a known good state. These backups can't be renamed, so we just keep them separate until approval.</li> </ol>"},{"location":"scaffolding/pkg_exportedobjects/","title":"Exported Objects package","text":"<p>Even though the CLI does not provide scaffolding for an <code>ExportedObjects</code> package, as it generally is better to include these in Master Data packages, it is possible to create such a package and the tool will pack it as with any other package type.</p> <p>As an example, an ExportedObjects package manifest looks like this:</p> <pre><code>{\n\"packageId\": \"Cmf.Custom.Baseline.ExportedObjects\",\n\"version\": \"1.0.0\",\n\"description\": \"Baseline Exported Objects Package\",\n\"packageType\": \"ExportedObjects\",\n\"isInstallable\": true,\n\"isUniqueInstall\": false,\n\"contentToPack\": [\n{\n\"source\": \"$(version)/*\",\n\"target\": \"ExportedObjects\"\n}\n]\n}\n</code></pre> <p>You would create a <code>cmfpackage.json</code> file inside the objects folder with this content. This will pack any XML file in a folder named after the current package version, so in this case <code>1.0.0</code> and place it in the package file in an <code>ExportedObjects</code> folder.</p> <p>Afterwards, do not forget to add this new package as a dependency of your root/feature package, to make sure it gets installed when required.</p>"},{"location":"scaffolding/post-scaffolding-package-tailoring/","title":"Post-scaffolding package tailoring","text":"<p>The packages generated by <code>cmf new</code> are as neutral as possible, so to be compatible with as many deployment scenarios as possible. However, some tailoring is advised for specific targets. This tailoring allows the packages to better adapt to their deployment target, eliminating the need of manual steps when installing.</p> <p>Below are some tailoring options for specific targets. It's recommended that these changes are applied according to your target environment.</p>"},{"location":"scaffolding/post-scaffolding-package-tailoring/#version-3x","title":"Version 3x:","text":""},{"location":"scaffolding/post-scaffolding-package-tailoring/#containers","title":"Containers:","text":"<ul> <li>Tests MasterData Package</li> <li>Add the property         <pre><code>\"isToSetDefaultSteps\": false\n</code></pre></li> </ul>"},{"location":"scaffolding/post-scaffolding-package-tailoring/#version-2x","title":"Version 2x:","text":""},{"location":"scaffolding/post-scaffolding-package-tailoring/#containers_1","title":"Containers:","text":"<ul> <li>Root Package</li> <li>Add to dependencies         <pre><code>\"dependencies\": [\n{ \"id\": \"Cmf.Environment\", \"version\": \"8.3.0\" }\n]\n</code></pre></li> <li>Business Package</li> <li>Add to steps:         <pre><code>\"steps\": [\n{ \"order\": \"1\", \"type\": \"DeployFiles\", \"ContentPath\": \"**/!(Cmf.Custom.*.BusinessObjects*).dll\" }\n]\n</code></pre></li> </ul>"},{"location":"scaffolding/post-scaffolding-package-tailoring/#deployment-framework","title":"Deployment Framework:","text":"<ul> <li>Root and IoT Root Package</li> <li>Add to dependencies         <pre><code>\"dependencies\": [\n{ \"id\": \"CriticalManufacturing.DeploymentMetadata\", \"version\": \"8.3.0\" }\n]\n</code></pre></li> <li>Business Package</li> <li>Add to steps:         <pre><code>\"steps\": [\n{ \"order\": 1, \"type\": \"Generic\", \"onExecute\": \"$(Agent.Root)/agent/scripts/stop_host.ps1\" },\n{ \"order\": 2, \"type\": \"DeployFiles\", \"ContentPath\": \"**/!(Cmf.Custom.*.BusinessObjects*).dll\" },\n{ \"order\": 3, \"type\": \"Generic\", \"onExecute\": \"$(Agent.Root)/agent/scripts/start_host.ps1\" }\n]\n</code></pre></li> <li>Data, IoTData and Tests MasterData Package<ul> <li>Add to steps:     <pre><code>\"steps\": [\n{ \"order\": 1, \"type\": \"Generic\", \"onExecute\": \"$(Agent.Root)/agent/scripts/stop_host.ps1\" },\n{ \"order\": 2, \"type\": \"TransformFile\", \"file\": \"Cmf.Foundation.Services.HostService.dll.config\", \"tagFile\": true },\n{ \"order\": 3, \"type\": \"Generic\", \"onExecute\": \"$(Agent.Root)/agent/scripts/start_host.ps1\" },\n{ \"order\": 4, \"type\": \"DeployFiles\", \"ContentPath\": \"GenerateLBOs.ps1\" },\n{ \"order\": 5, \"type\": \"Generic\", \"onExecute\": \"$(Package[Cmf.Custom.Package].TargetDirectory)/GenerateLBOs.ps1\" }\n]\n</code></pre></li> </ul> </li> </ul> <p>NOTE: Make sure that the order of the steps is the same referenced in this document.</p>"},{"location":"scaffolding/single/","title":"Traditional scaffolding","text":"<p>A \"traditional project\" does not contain feature packages, is developed entirely by one team in one repository and is delivered directly to one customer.</p> <p>These projects are usually composed of Business, UI, Help and Master Data customization, with optionally Exported Objects and IoT.</p> <p>The objective is to obtain a structure equivalent to what <code>solgen</code> provided.</p> <p>Please consult each commands help page for details of what each switch does.</p>"},{"location":"scaffolding/single/#initialize-the-repository","title":"Initialize the repository","text":"<p>These types of projects usually fully own their git repository and as such need to be initialized to obtain the base repo structure, as well as the build pipelines if we are targeting Azure DevOps.</p> <p>This is done with the <code>cmf init</code> command:</p> ClassicContainers <pre><code>cmf init Example `\n    --infra ..\\COMMON\\infrastructure\\CMF-internal.json `\n    -c Example.json `\n    --repositoryUrl https://tfs.criticalmanufacturing.com/Projects/Test/_git/Test `\n    --MESVersion 8.2.1 `\n    --DevTasksVersion 8.2.0 `\n    --HTMLStarterVersion 8.0.0 `\n    --yoGeneratorVersion 8.1.1 `\n    --nugetVersion 8.2.1 `\n    --testScenariosNugetVersion 8.2.1 `\n    --deploymentDir \\\\vm-project.criticalmanufacturing.com\\Deployments `\n    --ISOLocation \\\\setups\\CriticalManufacturing.iso `\n    --version 1.0.0\n</code></pre> <p><pre><code>cmf init Example `\n    --infra ..\\COMMON\\infrastructure\\CMF-internal.json `\n    -c Example.json `\n    --repositoryUrl https://tfs.criticalmanufacturing.com/Projects/Test/_git/Test `\n    --MESVersion 8.2.1 `\n    --DevTasksVersion 8.2.0 `\n    --HTMLStarterVersion 8.0.0 `\n    --yoGeneratorVersion 8.1.1 `\n    --nugetVersion 8.2.1 `\n    --testScenariosNugetVersion 8.2.1 `\n    --deploymentDir \\\\vm-project.criticalmanufacturing.com\\Deployments `\n    --ISOLocation \\\\setups\\CriticalManufacturing.iso `\n    --version 1.0.0 `\n    --releaseCustomerEnvironment EnvironmentName `\n    --releaseSite EnvironmentSite `\n    --releaseDeploymentPackage \\@criticalmanufacturing\\mes:8.3.1 `\n    --releaseLicense EnvironmentLicense `\n    --releaseDeploymentTarget EnvironmentTarget\n</code></pre> <code>EnvironmentTarget</code> can take any value recognized by the Portal SDK, which can be found here.</p> <p>Note: The <code>`</code> character escapes multiline commands in <code>powershell</code>. For bash, the <code>\\</code> character does the same thing.</p> <p>The infrastructure file specifies the repositories to be used to get the project dependencies. If you are scaffolding a Deployment Services project, there is a CMF-internal.json infra file which specifies our internal infrastructure. It's in the COMMON project, Tools repository, at <code>/infrastructure</code>. If scaffolding a customer or partner project, you will need to create this infrastructure file first. Check Infrastructure for more details.</p> <p>As in previous scenarios, the versions for the various input options must be previously determined. Unlike with <code>solgen</code>, <code>cmf init</code> will not assume default/current values for these options.</p> <p>This will also create a root package, which may or may not be shipped to the customer. Unlike with <code>solgen</code>, this root package has no dependencies, initially. Each time a layer package is created, it will be registered in the higher level package found. For a traditional repository, this will be the root package.</p> <p>If you are using version cmf-cli version 2x, follow the instructions defined in the Post-scaffolding package tailoring. You will not be able to generate the layer packages before doing this. In version 3, this is already done by the CLI.</p>"},{"location":"scaffolding/single/#layer-packages","title":"Layer packages","text":"<p>Each application layer is deployed in a different package. This allows the team to deliver only what was actively modified during a sprint, and keep the previous versions of the unchanged layers in an installed system.</p>"},{"location":"scaffolding/single/#business","title":"Business","text":"<p>The business package is straightforward and is generated with the <code>cmf new business</code> command:</p> <pre><code>cmf new business --version 1.0.0\n</code></pre> <p>This creates a .NET solution for backend development. Please note that unlike with <code>solgen</code>, the Actions project is not included in the business solution.</p>"},{"location":"scaffolding/single/#master-data","title":"Master Data","text":"<p>The Master Data package includes also the Exported Objects. Unlike in a <code>solgen</code> solution, Exported Objects are loaded via Master Data and not using a specific ExportedObjects sub-package.</p> <p>As the Master Data package also includes the Process Rules, it can optionally register the Actions package in a specific Business solution. For the traditional scenario, the command would be:</p> <pre><code>cmf new data --version 1.0.0 --businessPackage .\\Cmf.Custom.Business\\\n</code></pre>"},{"location":"scaffolding/single/#ui","title":"UI","text":"<p>The UI and Help packages are also scaffolded differently from a <code>solgen</code> project. To fully scaffold these solutions, the corresponding Deployment Framework package needs to be specified. These can be found in the MES ISO/disk. Make sure you use the correct version: a mismatch may cause all kinds of problems when running.</p> <p>The corresponding commands are:</p>"},{"location":"scaffolding/single/#html","title":"HTML","text":"<pre><code>cmf new html --version 1.0.0 --htmlPackage H:\\packages\\Cmf.Presentation.HTML.8.2.1.zip\n</code></pre> <p>If you require NPM registry authentication, the current procedure is to include the auth information in the apps\\customization.web.npmrc file as is standard.</p>"},{"location":"scaffolding/single/#help","title":"Help","text":"<pre><code>cmf new help --version 1.0.0 --documentationPackage H:\\packages\\Cmf.Documentation.8.2.1.zip\n</code></pre>"},{"location":"scaffolding/single/#iot","title":"IoT","text":"<p>The IoT package contains both IoTData and IoTPackages as sub-packages. They are always created together. <pre><code>cmf new iot --version 1.0.0\n</code></pre></p>"},{"location":"scaffolding/single/#database","title":"Database","text":"<p>The database package contains both Pre, Post and Reporting sub-packages. <pre><code>cmf new database --version 1.0.0\n</code></pre></p>"},{"location":"scaffolding/single/#tests","title":"Tests","text":"<p>The tests package is generated and built like any other layer package, but it is not installable. It is also not usually delivered to customers, unless requested. <pre><code>cmf new test --version 1.0.0\n</code></pre></p>"},{"location":"scaffolding/single/#demo","title":"Demo","text":"<p>This demo show the usual initial setup for a new project. For the first sprints, which focus heavily on modelling, the Data package is of the most importance. Obviously a Tests package is also needed. As an extra, the Business package is also initialized. This allows the Process Rules in the Data package to have a .NET solution where they can be compiled for checking.</p> <p>Note that the GIF is quite large and can take a bit to load.</p> <p></p>"}]}